{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e9ae87c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b197111f3dd1d21d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:23:38.643505Z",
     "start_time": "2024-02-09T04:23:10.263131Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220167a759cf381c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:23:49.123240Z",
     "start_time": "2024-02-09T04:23:49.078938Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook is to illustrate the Transformer architecture.\n",
    "Steps are followed by my article post: \n",
    "https://waylandzhang.github.io/en/let-s-code-llm.html\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adec81e8b065abf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:23:51.966821Z",
     "start_time": "2024-02-09T04:23:51.948834Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 4  # How many batches per training step\n",
    "context_length = 16  # Length of the token chunk each batch\n",
    "d_model = 64  # The vector size of the token embeddings\n",
    "num_layers = 8  # Number of transformer blocks\n",
    "num_heads = 4  # Number of heads in Multi-head attention # 我们的代码中通过 d_model / num_heads = 来获取 head_size\n",
    "learning_rate = 1e-3  # 0.001\n",
    "dropout = 0.1 # Dropout rate\n",
    "max_iters = 500  # Total of training iterations\n",
    "eval_interval = 50  # How often to evaluate the model \n",
    "eval_iters = 20  # How many iterations to average the loss over when evaluating the model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'  # Instead of using the cpu, we'll use the GPU if it's available.\n",
    "\n",
    "TORCH_SEED = 1337\n",
    "torch.manual_seed(TORCH_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:23:53.539657Z",
     "start_time": "2024-02-09T04:23:53.516333Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# download a sample txt file from https://huggingface.co/datasets/goendalf666/sales-textbook_for_convincing_and_selling/raw/main/sales_textbook.txt\n",
    "if not os.path.exists('data/sales_textbook.txt'):\n",
    "    url = 'https://huggingface.co/datasets/goendalf666/sales-textbook_for_convincing_and_selling/raw/main/sales_textbook.txt'\n",
    "    with open('sales_textbook.txt', 'w') as f:\n",
    "        f.write(requests.get(url).text)\n",
    "\n",
    "with open('data/sales_textbook.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eb984bfcb7a06b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:24:44.270382Z",
     "start_time": "2024-02-09T04:24:44.140668Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using TikToken to tokenize the source text\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "tokenized_text = encoding.encode(text)\n",
    "tokenized_text = torch.tensor(tokenized_text, dtype=torch.long, device=device) # Convert tokens into a tensor\n",
    "max_token_value = tokenized_text.max().item() # the maximum index value in our vocabulary\n",
    "\n",
    "print(f\"Tokenized text size: {len(tokenized_text)}\")\n",
    "print(f\"The maximum value in the tokenized text is: {max_token_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a059040",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text.max().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f1dbf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1453076ae7f2e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:24:50.051282Z",
     "start_time": "2024-02-09T04:24:50.032966Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Illustration purpose\n",
    "print(encoding.encode('Chapter 1: Building Rapport and Capturing'))\n",
    "print(encoding.decode([26072, 220, 16, 25, 17283, 23097, 403, 323, 17013, 1711])) # \"Rapport\" is tokenized as two tokens: \"Rap\"[23097] and \"port\"[403]\n",
    "print(encoding.decode([627, 1383, 88861, 279,1989, 315, 25607, 16940, 65931, 323, 32097, 11, 584, 26458, 13520, 449]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bd965d977d210d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:24:52.889469Z",
     "start_time": "2024-02-09T04:24:52.878327Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split train and validation\n",
    "split_idx = int(len(tokenized_text) * 0.9)\n",
    "train_data = tokenized_text[:split_idx]\n",
    "val_data = tokenized_text[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4d699c1f25bbe6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:25:08.155569Z",
     "start_time": "2024-02-09T04:25:08.138702Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare data for training batch\n",
    "data = train_data\n",
    "idxs = torch.randint(low=0, high=len(data) - context_length, size=(batch_size,))\n",
    "x_batch = torch.stack([data[idx:idx + context_length] for idx in idxs])\n",
    "y_batch = torch.stack([data[idx + 1:idx + context_length + 1] for idx in idxs])\n",
    "print(x_batch.shape, x_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96ee8f724daac71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:25:43.766159Z",
     "start_time": "2024-02-09T04:25:43.748077Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Illustration purpose\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "print(\"Our batches:\\n\", pd.DataFrame(x_batch.data.detach().cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9381d07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch.detach().cpu().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ade5a79e8c689ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:25:48.830907Z",
     "start_time": "2024-02-09T04:25:48.749815Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define Token Embedding look-up table\n",
    "token_embedding_lookup_table = nn.Embedding(max_token_value+1, d_model)\n",
    "print(\"Token Embedding Look-up table: \", token_embedding_lookup_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aa314dc5f6a76e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:25:54.090804Z",
     "start_time": "2024-02-09T04:25:54.057773Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get x and y embedding\n",
    "x_batch_embedding = token_embedding_lookup_table(x_batch.data) # [4, 16, 64] [batch_size, context_length, d_model]\n",
    "y_batch_embedding = token_embedding_lookup_table(y_batch.data)\n",
    "\n",
    "x_batch_embedding.shape, y_batch_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9bd1b4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f145bd89a13b23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:26:57.181192Z",
     "start_time": "2024-02-09T04:26:57.135243Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define Position Encoding look-up table\n",
    "position_encoding_lookup_table = torch.zeros(context_length, d_model)\n",
    "position = torch.arange(0, context_length, dtype=torch.float).unsqueeze(1)\n",
    "div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "position_encoding_lookup_table[:, 0::2] = torch.sin(position * div_term)\n",
    "position_encoding_lookup_table[:, 1::2] = torch.cos(position * div_term)\n",
    "position_encoding_lookup_table = position_encoding_lookup_table.unsqueeze(0).expand(batch_size, -1, -1) #add batch dimension\n",
    "\n",
    "print(\"Position Encoding Look-up Table: \", position_encoding_lookup_table.shape) # [4, 16, 64] [batch_size, context_length, d_model]\n",
    "pd.DataFrame(position_encoding_lookup_table[0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6ac3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "position.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf0de2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa43476e35fdb265",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:27:19.636816Z",
     "start_time": "2024-02-09T04:27:18.851615Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Illustration Purpose Only\n",
    "def visualize_pe(pe):\n",
    "    plt.imshow(pe, aspect=\"auto\")\n",
    "    plt.title(\"Positional Encoding\")\n",
    "    plt.xlabel(\"Encoding Dimension\")\n",
    "    plt.ylabel(\"Position Index\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "position_encoding_lookup_table2_np = position_encoding_lookup_table[0].cpu().numpy()\n",
    "visualize_pe(position_encoding_lookup_table2_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd545749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582a489e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc5355ba995b07b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:28:10.855919Z",
     "start_time": "2024-02-09T04:28:10.789425Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add positional encoding into the input embedding vector\n",
    "input_embedding_x = x_batch_embedding + position_encoding_lookup_table # [4, 16, 64] [batch_size, context_length, d_model]\n",
    "input_embedding_y = y_batch_embedding + position_encoding_lookup_table\n",
    "pd.DataFrame(input_embedding_x[0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49bfcfcb646b81f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:28:49.421348Z",
     "start_time": "2024-02-09T04:28:49.395576Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare Query, Key, Value for Multi-head Attention\n",
    "X = input_embedding_x\n",
    "query = key = value = X # [4, 16, 64] [batch_size, context_length, d_model]\n",
    "query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ba89375b2f44ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:28:52.125568Z",
     "start_time": "2024-02-09T04:28:51.769196Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define Query, Key, Value weight matrices\n",
    "Wq = nn.Linear(d_model, d_model)\n",
    "Wk = nn.Linear(d_model, d_model)\n",
    "Wv = nn.Linear(d_model, d_model)\n",
    "\n",
    "Q = Wq(query) #[4, 16, 64]\n",
    "Q = Q.view(batch_size, -1, num_heads, d_model // num_heads)  #[4, 16, 4, 16]\n",
    "\n",
    "K = Wk(key) #[4, 16, 64]\n",
    "K = K.view(batch_size, -1, num_heads, d_model // num_heads)  #[4, 16, 4, 16]\n",
    "\n",
    "V = Wv(value) #[4, 16, 64]\n",
    "V = V.view(batch_size, -1, num_heads, d_model // num_heads)  #[4, 16, 4, 16]\n",
    "\n",
    "# print(torch.round(Q[0] * 100) / 100)\n",
    "qqq = Q.detach().cpu().numpy()\n",
    "for qs in qqq:\n",
    "    for qss in qs:\n",
    "        print(pd.DataFrame(qss))\n",
    "\n",
    "print(Q.shape) # [4, 16, 4, 16] [batch_size, context_length, num_heads, head_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6b2187b2d310a2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:29:30.525962Z",
     "start_time": "2024-02-09T04:29:30.508654Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Transpose q,k,v from [batch_size, context_length, num_heads, head_size] to [batch_size, num_heads, context_length, head_size]\n",
    "# The reason is that treat each batch with \"num_heads\" as its first dimension.\n",
    "Q = Q.transpose(1, 2) # [4, 4, 16, 16]\n",
    "K = K.transpose(1, 2) # [4, 4, 16, 16]\n",
    "V = V.transpose(1, 2) # [4, 4, 16, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd5217e3fa43d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:31:11.625621Z",
     "start_time": "2024-02-09T04:31:11.196103Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate the attention score\n",
    "attention_score = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_model // num_heads) # [4, 4, 16, 16]\n",
    "\n",
    "# Illustration only\n",
    "plt.imshow(attention_score[1, 1].detach().cpu().numpy(), \"Accent\", aspect=\"auto\")\n",
    "plt.title(\"Attention(Q @ K)\") #plot attention in the first head of the first batch\n",
    "plt.xlabel(encoding.decode(x_batch[0].tolist()))\n",
    "plt.ylabel(encoding.decode(x_batch[0].tolist()))\n",
    "plt.colorbar()\n",
    "pd.DataFrame(attention_score[0][0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9958625c65291f4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:31:43.305491Z",
     "start_time": "2024-02-09T04:31:42.713623Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Apply Mask to attention scores\n",
    "attention_score = attention_score.masked_fill(torch.triu(torch.ones(attention_score.shape[-2:]), diagonal=1).bool(), float('-inf'))#[4, 4, 16, 16] [batch_size, num_heads, context_length, context_length]\n",
    "\n",
    "# Illustration only\n",
    "plt.imshow(attention_score[1, 1].detach().cpu().numpy(), \"Accent\", aspect=\"auto\")\n",
    "plt.title(\"Attention(Q,K)\")\n",
    "plt.xlabel(encoding.decode(x_batch[0].tolist()))\n",
    "plt.ylabel(encoding.decode(x_batch[0].tolist()))\n",
    "plt.colorbar()\n",
    "pd.DataFrame(attention_score[0][0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb3f22c3466b59b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:32:08.443877Z",
     "start_time": "2024-02-09T04:32:08.408750Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Softmax the attention score\n",
    "attention_score = torch.softmax(attention_score, dim=-1) #[4, 4, 16, 16] [batch_size, num_heads, context_length, context_length]\n",
    "pd.DataFrame(attention_score[0][0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a14ab6238d8f340",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:32:19.745362Z",
     "start_time": "2024-02-09T04:32:19.729817Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate the V attention output\n",
    "print(attention_score.shape) #[4, 4, 16, 16] [batch_size, num_heads, context_length, context_length]\n",
    "print(V.shape) #[4, 4, 16, 16] [batch_size, num_heads, context_length, head_size]\n",
    "A = torch.matmul(attention_score, V) # [4, 4, 16, 16] [batch_size, num_heads, context_length, head_size]\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57894d06f08e7f5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:32:38.040254Z",
     "start_time": "2024-02-09T04:32:37.994213Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Concatenate the attention output\n",
    "A = A.transpose(1, 2) # [4, 16, 4, 16] [batch_size, context_length, num_heads, head_size]\n",
    "A = A.reshape(batch_size, -1, d_model) # [4, 16, 64] [batch_size, context_length, d_model]\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4fbfce6f7f330a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:33:01.895820Z",
     "start_time": "2024-02-09T04:33:01.830312Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the output weight matrix\n",
    "Wo = nn.Linear(d_model, d_model)\n",
    "output = Wo(A) # [4, 16, 64] [batch_size, context_length, d_model]\n",
    "print(output.shape)\n",
    "pd.DataFrame(output[0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2835a23754fafc42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:34:34.038171Z",
     "start_time": "2024-02-09T04:34:34.029896Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add residual connection\n",
    "output = output + X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7761664159de5538",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:34:34.636527Z",
     "start_time": "2024-02-09T04:34:34.608438Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add Layer Normalization\n",
    "layer_norm = nn.LayerNorm(d_model)\n",
    "output_layernorm = layer_norm(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ce7c56ac3de91a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:34:35.139721Z",
     "start_time": "2024-02-09T04:34:35.110122Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define Feed Forward Network\n",
    "output = nn.Linear(d_model, d_model * 4)(output_layernorm)\n",
    "output = nn.ReLU()(output)\n",
    "output = nn.Linear(d_model * 4, d_model)(output)\n",
    "output = torch.dropout(output, p=dropout, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cce4d92eeb74ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:35:25.104704Z",
     "start_time": "2024-02-09T04:35:25.076394Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add residual connection & layerNorm (last time in a Transformer block)\n",
    "output = output + output_layernorm\n",
    "# Add Layer Normalization\n",
    "layer_norm = nn.LayerNorm(d_model)\n",
    "output = layer_norm(output)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a0de0adb842207e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:35:25.618791Z",
     "start_time": "2024-02-09T04:35:25.608096Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Until here, we finished a Transformer block,\n",
    "# We actually should pack the above Transformer block code into a call and \n",
    "# repeat the steps for num_layers times\n",
    "# but this jupyter notebook is purely for illustration purpose, so we'll skip it:\n",
    "# for _ in range(num_layers):\n",
    "#   do loop for each transformer block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4b434e547757",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:35:26.555049Z",
     "start_time": "2024-02-09T04:35:26.440498Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Apply the final linear layer to get the logits\n",
    "logits = nn.Linear(d_model, max_token_value+1)(output)\n",
    "pd.DataFrame(logits[0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a857abd1cceecb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:35:46.352818Z",
     "start_time": "2024-02-09T04:35:46.256747Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the probabilities \n",
    "# torch.softmax usually used during inference, during training we use torch.nn.CrossEntropyLoss\n",
    "# but for illustration purpose, we'll use torch.softmax here\n",
    "probabilities = torch.softmax(logits, dim=-1)\n",
    "pd.DataFrame(probabilities[0].detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de9e0455613f790",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:36:08.064535Z",
     "start_time": "2024-02-09T04:36:08.045119Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's see the predicted token and it's original English word\n",
    "predicted_index = torch.argmax(logits[0,0]).item()\n",
    "encoding.decode([predicted_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329ff8f3529b7309",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:39:04.969636Z",
     "start_time": "2024-02-09T04:39:04.925038Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's see the original input sentence\n",
    "encoding.decode(x_batch[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111989a98903f4dd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Looks like the predicted token \"Catholics\" is not the correct prediction token to the original sentence, because we only did one training loop and barely trained nothing.\n",
    "# But this is the basic idea of how the Transformer works.\n",
    "# We'll continue to train the model in the next notebook and wrap the above code into a class.\n",
    "# https://waylandzhang.github.io/en/let-s-code-llm.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
