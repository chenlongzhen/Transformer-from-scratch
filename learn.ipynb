{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook is to illustrate the Transformer architecture.\n",
    "Steps are followed by my article post: \n",
    "https://waylandzhang.github.io/en/let-s-code-llm.html\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 4  # How many batches per training step\n",
    "context_length = 16  # Length of the token chunk each batch\n",
    "d_model = 64  # The vector size of the token embeddings\n",
    "num_layers = 8  # Number of transformer blocks\n",
    "num_heads = 4  # Number of heads in Multi-head attention # 我们的代码中通过 d_model / num_heads = 来获取 head_size\n",
    "learning_rate = 1e-3  # 0.001\n",
    "dropout = 0.1 # Dropout rate\n",
    "max_iters = 500  # Total of training iterations\n",
    "eval_interval = 50  # How often to evaluate the model \n",
    "eval_iters = 20  # How many iterations to average the loss over when evaluating the model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'  # Instead of using the cpu, we'll use the GPU if it's available.\n",
    "\n",
    "TORCH_SEED = 1337\n",
    "torch.manual_seed(TORCH_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download a sample txt file from https://huggingface.co/datasets/goendalf666/sales-textbook_for_convincing_and_selling/raw/main/sales_textbook.txt\n",
    "if not os.path.exists('data/sales_textbook.txt'):\n",
    "    url = 'https://huggingface.co/datasets/goendalf666/sales-textbook_for_convincing_and_selling/raw/main/sales_textbook.txt'\n",
    "    with open('sales_textbook.txt', 'w') as f:\n",
    "        f.write(requests.get(url).text)\n",
    "\n",
    "with open('data/sales_textbook.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using TikToken to tokenize the source text\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "tokenized_text = encoding.encode(text)\n",
    "tokenized_text = torch.tensor(tokenized_text, dtype=torch.long, device=device) # Convert tokens into a tensor\n",
    "max_token_value = tokenized_text.max().item() # the maximum index value in our vocabulary\n",
    "\n",
    "print(f\"Tokenized text size: {len(tokenized_text)}\")\n",
    "print(f\"The maximum value in the tokenized text is: {max_token_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text.max().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Illustration purpose\n",
    "print(encoding.encode('测试aaa中国你好'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoding.decode([82805, 33746, 59795])) # \"Rapport\" is tokenized as two tokens: \"Rap\"[23097] and \"port\"[403]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and validation\n",
    "split_idx = int(len(tokenized_text) * 0.9)\n",
    "train_data = tokenized_text[:split_idx]\n",
    "val_data = tokenized_text[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training batch\n",
    "data = train_data\n",
    "idxs = torch.randint(low=0, high=len(data) - context_length, size=(batch_size,))\n",
    "x_batch = torch.stack([data[idx:idx + context_length] for idx in idxs])\n",
    "y_batch = torch.stack([data[idx + 1:idx + context_length + 1] for idx in idxs])\n",
    "print(x_batch.shape, x_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Illustration purpose\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "print(\"Our batches:\\n\", pd.DataFrame(x_batch.data.detach().cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Token Embedding look-up table\n",
    "token_embedding_lookup_table = nn.Embedding(max_token_value+1, d_model)\n",
    "print(\"Token Embedding Look-up table: \", token_embedding_lookup_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch.data.numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get x and y embedding\n",
    "x_batch_embedding = token_embedding_lookup_table(x_batch.data) # [4, 16, 64] [batch_size, context_length, d_model]\n",
    "y_batch_embedding = token_embedding_lookup_table(y_batch.data)\n",
    "\n",
    "x_batch_embedding.shape, y_batch_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = torch.zeros(context_length, d_model)\n",
    "position = torch.arange(0, context_length, dtype=torch.float)\n",
    "div_term = torch.exp(torch.arange(0, d_model, 2).float() * \n",
    "                     (-math.log(10000)/d_model))\n",
    "P[:,0::2] = torch.sin(position.unsqueeze(1) * div_term)\n",
    "P[:,1::2] = torch.cos(position.unsqueeze(1) * div_term)\n",
    "position_encoding_lookup_table = P.unsqueeze(0).expand(batch_size, -1, -1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=position.unsqueeze(1) * div_term\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Illustration Purpose Only\n",
    "def visualize_pe(pe):\n",
    "    plt.imshow(pe, aspect=\"auto\")\n",
    "    plt.title(\"Positional Encoding\")\n",
    "    plt.xlabel(\"Encoding Dimension\")\n",
    "    plt.ylabel(\"Position Index\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "position_encoding_lookup_table2_np = position_encoding_lookup_table[0].cpu().numpy()\n",
    "visualize_pe(position_encoding_lookup_table2_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embedding_x = x_batch_embedding + position_encoding_lookup_table\n",
    "input_embedding_y = y_batch_embedding + position_encoding_lookup_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = input_embedding_x\n",
    "query = key = value = X\n",
    "query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wq = nn.Linear(d_model, d_model)\n",
    "Wk = nn.Linear(d_model, d_model)\n",
    "Wv = nn.Linear(d_model, d_model)\n",
    "\n",
    "Q = Wq(query)\n",
    "Q = Q.view(batch_size, context_length, num_heads, d_model//num_heads)\n",
    "\n",
    "\n",
    "K = Wk(key)\n",
    "K = K.view(batch_size, context_length, num_heads, d_model//num_heads)\n",
    "\n",
    "\n",
    "V= Wv(value)\n",
    "V = V.view(batch_size, context_length, num_heads, d_model//num_heads)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = Q.transpose(1,2) # head和length转置\n",
    "K = K.transpose(1,2) # head和length转置\n",
    "V = V.transpose(1,2) # head和length转置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "attenstion_score = torch.matmul(Q, K.transpose(2,3)/math.sqrt(d_model//num_heads))\n",
    "\n",
    "attenstion_score[0,0].detach().cpu().numpy()\n",
    "# Illustration only\n",
    "plt.imshow(attenstion_score[0, 0].detach().cpu().numpy(), \"Accent\", aspect=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = torch.triu(torch.ones(attenstion_score.shape[-2:]),diagonal=1).bool()\n",
    "attention_score = attenstion_score.masked_fill(tr, float('-inf'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Illustration only\n",
    "# -inf 是因为要取e，然后才是0\n",
    "plt.imshow(attention_score[1, 1].detach().cpu().numpy(), \"Accent\", aspect=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_score = torch.softmax(attenstion_score, dim=-1)\n",
    "A = torch.matmul(attention_score, V) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(attention_score[0,0].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_score[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = A.transpose(1,2).contiguous()\n",
    "A = A.view(batch_size, -1, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wo = nn.Linear(d_model, d_model)\n",
    "output = Wo(A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output + X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_norm = nn.LayerNorm(d_model)\n",
    "output_layernorm = layer_norm(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outout  = nn.Linear(d_model, d_model*4)(output_layernorm)\n",
    "output = nn.ReLU()(output)\n",
    "output = nn.Linear(d_model*4, d_model)(output)\n",
    "output = output + output_layernorm\n",
    "output = layer_norm(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits  = nn.Linear(d_model, max_token_value+1)(output)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = torch.softmax(logits, dim=-1)\n",
    "pd.DataFrame(prob[0].detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_index = torch.argmax(logits[0,15]).item()\n",
    "encoding.decode([predicted_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the original input sentence\n",
    "encoding.decode(x_batch[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
